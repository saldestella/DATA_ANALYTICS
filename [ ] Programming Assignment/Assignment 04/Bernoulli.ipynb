{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2c6b50d",
   "metadata": {},
   "source": [
    "$\\textbf{PROGRAMMING #4 ASSIGNMENT}$\n",
    "---\n",
    "         \n",
    "1. Read the Bernoulli Mixture Model Derivation.\n",
    "2. Read about Stochastic Expectation-Maximization (EM) Algorithm: https://www.sciencedirect.com/science/article/pii/S0167947320302504.\n",
    "3. From the given code, modify the EM algorithm to become a Stochastic EM Algorithm.\n",
    "4. Use the data from the paper: https://www.sciencedirect.com/science/article/abs/pii/S0031320322001753\n",
    "5. Perform categorical clustering using the Bernoulli Mixture Model with Stochastic EM Algorithm.\n",
    "6. Compare its performance with K-Modes Algorithm using Folkes-Mallows Index, Adjusted Rand Index, and Normalized Mutual Information Score.\n",
    "7. Compare and contrast the performances, and explain what is happening (i.e. why is FMI always higher than ARI and NMI? Why is ARI and NMI low compared to FMI? etc.)\n",
    "8. Write the report in Latex, push to your github with the codes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2f5050-0d8a-420a-bd2d-4d6882061d11",
   "metadata": {},
   "source": [
    "Initial Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b95d50a1-1271-4fc3-8712-7c7e35d5740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import itertools\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import requests\n",
    "from kmodes.kmodes import KModes\n",
    "from sklearn.metrics import adjusted_rand_score as ARI, normalized_mutual_info_score as NMI, fowlkes_mallows_score as FMI\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e505957-802a-4f5d-8800-6fd35fe05291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd0f012d-2bd8-4064-932e-f635034f25d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the true number of cluster for each dataset\n",
    "num_clusters_dict = {\n",
    "    \"Soybean\": 4,\n",
    "    \"Zoo\": 7,\n",
    "    \"Heart Disease\": 2,\n",
    "    \"Breast Cancer\": 2,\n",
    "    \"Dermatology\": 6,\n",
    "    \"Letters(E, F)\": 2,\n",
    "    \"DNA\": 3,\n",
    "    \"Mushroom\": 2,\n",
    "    \"Iris\": 3,\n",
    "    \"Isolet\": 26,\n",
    "    \"Optical\": 10,\n",
    "    \"PenDigits\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4cf08a4-326b-4425-9374-cc42db44dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of datasets for clustering ensemble task\n",
    "datasets_ensemble = [\n",
    "    \"Iris\",\n",
    "    \"Isolet\",\n",
    "    \"Optical\",\n",
    "    \"PenDigits\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b68d4497-b402-4454-b12e-8df71a905793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of runs for benchmarking\n",
    "num_runs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c433a052-c8a0-4138-aecf-adab9e1b5441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dictionary to hold raw dataframes\n",
    "raw_dataframes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c6f588a-efb2-474d-8e2c-42e6faba77ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataframes[\"Soybean\"] = pd.read_csv(\"https://archive.ics.uci.edu/static/public/91/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "528643e7-b0a7-471e-8cfe-b8f9530c872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataframes[\"Zoo\"] = pd.read_csv(\"https://archive.ics.uci.edu/static/public/111/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f3b5b0e-df83-4623-8333-0e4d122d69db",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataframes[\"Heart Disease\"] = pd.read_csv(\"https://archive.ics.uci.edu/static/public/45/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39df2a87-1bc3-462c-bc76-b29b57d19d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataframes[\"Breast Cancer\"] = pd.read_csv(\"https://archive.ics.uci.edu/static/public/15/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bb2bf2f-fe71-4745-98aa-2341923b2322",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataframes[\"Dermatology\"] = pd.read_csv(\"https://archive.ics.uci.edu/static/public/33/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed71af64-12e8-42db-b797-beb50d99f637",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataframes[\"Letters(E, F)\"] = pd.read_csv(\"https://archive.ics.uci.edu/static/public/59/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee9d88bf-b1c2-4e3d-916c-aaa32a54599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataframes[\"DNA\"] = pd.read_csv(\"https://archive.ics.uci.edu/static/public/69/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c28ae29-1a3b-4a39-9d87-1b84f167c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataframes[\"Mushroom\"] = pd.read_csv(\"https://archive.ics.uci.edu/static/public/73/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92e371f0-56f5-41c4-bd4c-3614c48dfbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataframes[\"Iris\"] = pd.read_csv(\"https://archive.ics.uci.edu/static/public/53/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc1fd850-35b4-43b7-8bd1-fcc825827bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataframes[\"Isolet\"] = pd.read_csv(\"isolet5.data\", nrows=1560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1ca57d9-0f7b-4b59-b264-b968bc5d4325",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataframes[\"Optical\"] = pd.read_csv(\"https://archive.ics.uci.edu/static/public/80/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f27f6af6-0c46-4a57-999a-6bc2f4494ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataframes[\"PenDigits\"] = pd.read_csv(\"https://archive.ics.uci.edu/static/public/81/data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc70d31a-dd20-4e4d-87d7-35c55b6dff51",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb75f9f1-d83b-4ed6-8ff0-96bd175d080e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping rows with NaNs in Soybean:\n",
      "Shape of features (X): (47, 21)\n",
      "Shape of targets (y): (47,)\n",
      "NaN counts per column:\n",
      " date               0\n",
      "plant-stand        0\n",
      "precip             0\n",
      "temp               0\n",
      "hail               0\n",
      "crop-hist          0\n",
      "area-damaged       0\n",
      "severity           0\n",
      "seed-tmt           0\n",
      "germination        0\n",
      "leaves             0\n",
      "lodging            0\n",
      "stem-cankers       0\n",
      "canker-lesion      0\n",
      "fruiting-bodies    0\n",
      "external-decay     0\n",
      "mycelium           0\n",
      "int-discolor       0\n",
      "sclerotia          0\n",
      "fruit-pods         0\n",
      "roots              0\n",
      "dtype: int64\n",
      "After dropping rows with NaNs in Soybean:\n",
      "Shape of features (X): (47, 21)\n",
      "Shape of targets (y): (47,)\n",
      "NaN counts per column:\n",
      " date               0\n",
      "plant-stand        0\n",
      "precip             0\n",
      "temp               0\n",
      "hail               0\n",
      "crop-hist          0\n",
      "area-damaged       0\n",
      "severity           0\n",
      "seed-tmt           0\n",
      "germination        0\n",
      "leaves             0\n",
      "lodging            0\n",
      "stem-cankers       0\n",
      "canker-lesion      0\n",
      "fruiting-bodies    0\n",
      "external-decay     0\n",
      "mycelium           0\n",
      "int-discolor       0\n",
      "sclerotia          0\n",
      "fruit-pods         0\n",
      "roots              0\n",
      "dtype: int64\n",
      "Before dropping rows with NaNs in Zoo:\n",
      "Shape of features (X): (101, 17)\n",
      "Shape of targets (y): (101,)\n",
      "NaN counts per column:\n",
      " animal_name    0\n",
      "hair           0\n",
      "feathers       0\n",
      "eggs           0\n",
      "milk           0\n",
      "airborne       0\n",
      "aquatic        0\n",
      "predator       0\n",
      "toothed        0\n",
      "backbone       0\n",
      "breathes       0\n",
      "venomous       0\n",
      "fins           0\n",
      "legs           0\n",
      "tail           0\n",
      "domestic       0\n",
      "catsize        0\n",
      "dtype: int64\n",
      "After dropping rows with NaNs in Zoo:\n",
      "Shape of features (X): (101, 17)\n",
      "Shape of targets (y): (101,)\n",
      "NaN counts per column:\n",
      " animal_name    0\n",
      "hair           0\n",
      "feathers       0\n",
      "eggs           0\n",
      "milk           0\n",
      "airborne       0\n",
      "aquatic        0\n",
      "predator       0\n",
      "toothed        0\n",
      "backbone       0\n",
      "breathes       0\n",
      "venomous       0\n",
      "fins           0\n",
      "legs           0\n",
      "tail           0\n",
      "domestic       0\n",
      "catsize        0\n",
      "dtype: int64\n",
      "Before dropping rows with NaNs in Heart Disease:\n",
      "Shape of features (X): (303, 13)\n",
      "Shape of targets (y): (303,)\n",
      "NaN counts per column:\n",
      " age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          4\n",
      "thal        2\n",
      "dtype: int64\n",
      "After dropping rows with NaNs in Heart Disease:\n",
      "Shape of features (X): (297, 13)\n",
      "Shape of targets (y): (297,)\n",
      "NaN counts per column:\n",
      " age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "dtype: int64\n",
      "Before dropping rows with NaNs in Breast Cancer:\n",
      "Shape of features (X): (699, 10)\n",
      "Shape of targets (y): (699,)\n",
      "NaN counts per column:\n",
      " Sample_code_number              0\n",
      "Clump_thickness                 0\n",
      "Uniformity_of_cell_size         0\n",
      "Uniformity_of_cell_shape        0\n",
      "Marginal_adhesion               0\n",
      "Single_epithelial_cell_size     0\n",
      "Bare_nuclei                    16\n",
      "Bland_chromatin                 0\n",
      "Normal_nucleoli                 0\n",
      "Mitoses                         0\n",
      "dtype: int64\n",
      "After dropping rows with NaNs in Breast Cancer:\n",
      "Shape of features (X): (683, 10)\n",
      "Shape of targets (y): (683,)\n",
      "NaN counts per column:\n",
      " Sample_code_number             0\n",
      "Clump_thickness                0\n",
      "Uniformity_of_cell_size        0\n",
      "Uniformity_of_cell_shape       0\n",
      "Marginal_adhesion              0\n",
      "Single_epithelial_cell_size    0\n",
      "Bare_nuclei                    0\n",
      "Bland_chromatin                0\n",
      "Normal_nucleoli                0\n",
      "Mitoses                        0\n",
      "dtype: int64\n",
      "Before dropping rows with NaNs in Dermatology:\n",
      "Shape of features (X): (366, 34)\n",
      "Shape of targets (y): (366,)\n",
      "NaN counts per column:\n",
      " erythema                                       0\n",
      "scaling                                        0\n",
      "definite-borders                               0\n",
      "itching                                        0\n",
      "koebner phenomenon                             0\n",
      "polygonal papules                              0\n",
      "follicular papules                             0\n",
      "oral-mucosal involvement                       0\n",
      "knee elbow involvement                         0\n",
      "scalp involvement                              0\n",
      "family history                                 0\n",
      "melanin incontinence                           0\n",
      "eosinophils in the infiltrate                  0\n",
      "pnl infiltrate                                 0\n",
      "fibrosis of the papillary dermis               0\n",
      "exocytosis                                     0\n",
      "acanthosis                                     0\n",
      "hyperkeratosis                                 0\n",
      "parakeratosis                                  0\n",
      "clubbing of the rete ridges                    0\n",
      "elongation of the rete ridges                  0\n",
      "thinning of the suprapapillary epidermis       0\n",
      "spongiform pustule                             0\n",
      "munro microabcess                              0\n",
      "focal hypergranulosis                          0\n",
      "disappearance of the granular layer            0\n",
      "vacuolisation and damage of the basal layer    0\n",
      "spongiosis                                     0\n",
      "saw-tooth appearance of retes                  0\n",
      "follicular horn plug                           0\n",
      "perifollicular parakeratosis                   0\n",
      "inflammatory monoluclear infiltrate            0\n",
      "band-like infiltrate                           0\n",
      "age                                            8\n",
      "dtype: int64\n",
      "After dropping rows with NaNs in Dermatology:\n",
      "Shape of features (X): (358, 34)\n",
      "Shape of targets (y): (358,)\n",
      "NaN counts per column:\n",
      " erythema                                       0\n",
      "scaling                                        0\n",
      "definite-borders                               0\n",
      "itching                                        0\n",
      "koebner phenomenon                             0\n",
      "polygonal papules                              0\n",
      "follicular papules                             0\n",
      "oral-mucosal involvement                       0\n",
      "knee elbow involvement                         0\n",
      "scalp involvement                              0\n",
      "family history                                 0\n",
      "melanin incontinence                           0\n",
      "eosinophils in the infiltrate                  0\n",
      "pnl infiltrate                                 0\n",
      "fibrosis of the papillary dermis               0\n",
      "exocytosis                                     0\n",
      "acanthosis                                     0\n",
      "hyperkeratosis                                 0\n",
      "parakeratosis                                  0\n",
      "clubbing of the rete ridges                    0\n",
      "elongation of the rete ridges                  0\n",
      "thinning of the suprapapillary epidermis       0\n",
      "spongiform pustule                             0\n",
      "munro microabcess                              0\n",
      "focal hypergranulosis                          0\n",
      "disappearance of the granular layer            0\n",
      "vacuolisation and damage of the basal layer    0\n",
      "spongiosis                                     0\n",
      "saw-tooth appearance of retes                  0\n",
      "follicular horn plug                           0\n",
      "perifollicular parakeratosis                   0\n",
      "inflammatory monoluclear infiltrate            0\n",
      "band-like infiltrate                           0\n",
      "age                                            0\n",
      "dtype: int64\n",
      "Before dropping rows with NaNs in Letters(E, F):\n",
      "Shape of features (X): (1543, 16)\n",
      "Shape of targets (y): (1543,)\n",
      "NaN counts per column:\n",
      " x-box    0\n",
      "y-box    0\n",
      "width    0\n",
      "high     0\n",
      "onpix    0\n",
      "x-bar    0\n",
      "y-bar    0\n",
      "x2bar    0\n",
      "y2bar    0\n",
      "xybar    0\n",
      "x2ybr    0\n",
      "xy2br    0\n",
      "x-ege    0\n",
      "xegvy    0\n",
      "y-ege    0\n",
      "yegvx    0\n",
      "dtype: int64\n",
      "After dropping rows with NaNs in Letters(E, F):\n",
      "Shape of features (X): (1543, 16)\n",
      "Shape of targets (y): (1543,)\n",
      "NaN counts per column:\n",
      " x-box    0\n",
      "y-box    0\n",
      "width    0\n",
      "high     0\n",
      "onpix    0\n",
      "x-bar    0\n",
      "y-bar    0\n",
      "x2bar    0\n",
      "y2bar    0\n",
      "xybar    0\n",
      "x2ybr    0\n",
      "xy2br    0\n",
      "x-ege    0\n",
      "xegvy    0\n",
      "y-ege    0\n",
      "yegvx    0\n",
      "dtype: int64\n",
      "Before dropping rows with NaNs in DNA:\n",
      "Shape of features (X): (3190, 60)\n",
      "Shape of targets (y): (3190,)\n",
      "NaN counts per column:\n",
      " Base1     0\n",
      "Base2     0\n",
      "Base3     0\n",
      "Base4     0\n",
      "Base5     0\n",
      "Base6     0\n",
      "Base7     0\n",
      "Base8     0\n",
      "Base9     0\n",
      "Base10    0\n",
      "Base11    0\n",
      "Base12    0\n",
      "Base13    0\n",
      "Base14    0\n",
      "Base15    0\n",
      "Base16    0\n",
      "Base17    0\n",
      "Base18    0\n",
      "Base19    0\n",
      "Base20    0\n",
      "Base21    0\n",
      "Base22    0\n",
      "Base23    0\n",
      "Base24    0\n",
      "Base25    0\n",
      "Base26    0\n",
      "Base27    0\n",
      "Base28    0\n",
      "Base29    0\n",
      "Base30    0\n",
      "Base31    0\n",
      "Base32    0\n",
      "Base33    0\n",
      "Base34    0\n",
      "Base35    0\n",
      "Base36    0\n",
      "Base37    0\n",
      "Base38    0\n",
      "Base39    0\n",
      "Base40    0\n",
      "Base41    0\n",
      "Base42    0\n",
      "Base43    0\n",
      "Base44    0\n",
      "Base45    0\n",
      "Base46    0\n",
      "Base47    0\n",
      "Base48    0\n",
      "Base49    0\n",
      "Base50    0\n",
      "Base51    0\n",
      "Base52    0\n",
      "Base53    0\n",
      "Base54    0\n",
      "Base55    0\n",
      "Base56    0\n",
      "Base57    0\n",
      "Base58    0\n",
      "Base59    0\n",
      "Base60    0\n",
      "dtype: int64\n",
      "After dropping rows with NaNs in DNA:\n",
      "Shape of features (X): (3190, 60)\n",
      "Shape of targets (y): (3190,)\n",
      "NaN counts per column:\n",
      " Base1     0\n",
      "Base2     0\n",
      "Base3     0\n",
      "Base4     0\n",
      "Base5     0\n",
      "Base6     0\n",
      "Base7     0\n",
      "Base8     0\n",
      "Base9     0\n",
      "Base10    0\n",
      "Base11    0\n",
      "Base12    0\n",
      "Base13    0\n",
      "Base14    0\n",
      "Base15    0\n",
      "Base16    0\n",
      "Base17    0\n",
      "Base18    0\n",
      "Base19    0\n",
      "Base20    0\n",
      "Base21    0\n",
      "Base22    0\n",
      "Base23    0\n",
      "Base24    0\n",
      "Base25    0\n",
      "Base26    0\n",
      "Base27    0\n",
      "Base28    0\n",
      "Base29    0\n",
      "Base30    0\n",
      "Base31    0\n",
      "Base32    0\n",
      "Base33    0\n",
      "Base34    0\n",
      "Base35    0\n",
      "Base36    0\n",
      "Base37    0\n",
      "Base38    0\n",
      "Base39    0\n",
      "Base40    0\n",
      "Base41    0\n",
      "Base42    0\n",
      "Base43    0\n",
      "Base44    0\n",
      "Base45    0\n",
      "Base46    0\n",
      "Base47    0\n",
      "Base48    0\n",
      "Base49    0\n",
      "Base50    0\n",
      "Base51    0\n",
      "Base52    0\n",
      "Base53    0\n",
      "Base54    0\n",
      "Base55    0\n",
      "Base56    0\n",
      "Base57    0\n",
      "Base58    0\n",
      "Base59    0\n",
      "Base60    0\n",
      "dtype: int64\n",
      "Before dropping rows with NaNs in Mushroom:\n",
      "Shape of features (X): (8124, 21)\n",
      "Shape of targets (y): (8124,)\n",
      "NaN counts per column:\n",
      " cap-surface                    0\n",
      "cap-color                      0\n",
      "bruises                        0\n",
      "odor                           0\n",
      "gill-attachment                0\n",
      "gill-spacing                   0\n",
      "gill-size                      0\n",
      "gill-color                     0\n",
      "stalk-shape                    0\n",
      "stalk-root                  2480\n",
      "stalk-surface-above-ring       0\n",
      "stalk-surface-below-ring       0\n",
      "stalk-color-above-ring         0\n",
      "stalk-color-below-ring         0\n",
      "veil-color                     0\n",
      "ring-number                    0\n",
      "ring-type                      0\n",
      "spore-print-color              0\n",
      "population                     0\n",
      "habitat                        0\n",
      "poisonous                      0\n",
      "dtype: int64\n",
      "After dropping rows with NaNs in Mushroom:\n",
      "Shape of features (X): (5644, 21)\n",
      "Shape of targets (y): (5644,)\n",
      "NaN counts per column:\n",
      " cap-surface                 0\n",
      "cap-color                   0\n",
      "bruises                     0\n",
      "odor                        0\n",
      "gill-attachment             0\n",
      "gill-spacing                0\n",
      "gill-size                   0\n",
      "gill-color                  0\n",
      "stalk-shape                 0\n",
      "stalk-root                  0\n",
      "stalk-surface-above-ring    0\n",
      "stalk-surface-below-ring    0\n",
      "stalk-color-above-ring      0\n",
      "stalk-color-below-ring      0\n",
      "veil-color                  0\n",
      "ring-number                 0\n",
      "ring-type                   0\n",
      "spore-print-color           0\n",
      "population                  0\n",
      "habitat                     0\n",
      "poisonous                   0\n",
      "dtype: int64\n",
      "Before dropping rows with NaNs in Iris:\n",
      "Shape of features (X): (150, 4)\n",
      "Shape of targets (y): (150,)\n",
      "NaN counts per column:\n",
      " sepal length    0\n",
      "sepal width     0\n",
      "petal length    0\n",
      "petal width     0\n",
      "dtype: int64\n",
      "After dropping rows with NaNs in Iris:\n",
      "Shape of features (X): (150, 4)\n",
      "Shape of targets (y): (150,)\n",
      "NaN counts per column:\n",
      " sepal length    0\n",
      "sepal width     0\n",
      "petal length    0\n",
      "petal width     0\n",
      "dtype: int64\n",
      "Before dropping rows with NaNs in Isolet:\n",
      "Shape of features (X): (1558, 617)\n",
      "Shape of targets (y): (1558,)\n",
      "NaN counts per column:\n",
      " -0.2080     0\n",
      " 0.3480     0\n",
      " 0.3280     0\n",
      " 0.5040     0\n",
      " 0.9320     0\n",
      "           ..\n",
      " 0.1094     0\n",
      " 0.1718     0\n",
      " 0.1562     0\n",
      " 0.0468     0\n",
      " -0.3750    0\n",
      "Length: 617, dtype: int64\n",
      "After dropping rows with NaNs in Isolet:\n",
      "Shape of features (X): (1558, 617)\n",
      "Shape of targets (y): (1558,)\n",
      "NaN counts per column:\n",
      " -0.2080     0\n",
      " 0.3480     0\n",
      " 0.3280     0\n",
      " 0.5040     0\n",
      " 0.9320     0\n",
      "           ..\n",
      " 0.1094     0\n",
      " 0.1718     0\n",
      " 0.1562     0\n",
      " 0.0468     0\n",
      " -0.3750    0\n",
      "Length: 617, dtype: int64\n",
      "Before dropping rows with NaNs in Optical:\n",
      "Shape of features (X): (5620, 62)\n",
      "Shape of targets (y): (5620,)\n",
      "NaN counts per column:\n",
      " Attribute2     0\n",
      "Attribute3     0\n",
      "Attribute4     0\n",
      "Attribute5     0\n",
      "Attribute6     0\n",
      "              ..\n",
      "Attribute60    0\n",
      "Attribute61    0\n",
      "Attribute62    0\n",
      "Attribute63    0\n",
      "Attribute64    0\n",
      "Length: 62, dtype: int64\n",
      "After dropping rows with NaNs in Optical:\n",
      "Shape of features (X): (5620, 62)\n",
      "Shape of targets (y): (5620,)\n",
      "NaN counts per column:\n",
      " Attribute2     0\n",
      "Attribute3     0\n",
      "Attribute4     0\n",
      "Attribute5     0\n",
      "Attribute6     0\n",
      "              ..\n",
      "Attribute60    0\n",
      "Attribute61    0\n",
      "Attribute62    0\n",
      "Attribute63    0\n",
      "Attribute64    0\n",
      "Length: 62, dtype: int64\n",
      "Before dropping rows with NaNs in PenDigits:\n",
      "Shape of features (X): (10992, 16)\n",
      "Shape of targets (y): (10992,)\n",
      "NaN counts per column:\n",
      " Attribute1     0\n",
      "Attribute2     0\n",
      "Attribute3     0\n",
      "Attribute4     0\n",
      "Attribute5     0\n",
      "Attribute6     0\n",
      "Attribute7     0\n",
      "Attribute8     0\n",
      "Attribute9     0\n",
      "Attribute10    0\n",
      "Attribute11    0\n",
      "Attribute12    0\n",
      "Attribute13    0\n",
      "Attribute14    0\n",
      "Attribute15    0\n",
      "Attribute16    0\n",
      "dtype: int64\n",
      "After dropping rows with NaNs in PenDigits:\n",
      "Shape of features (X): (10992, 16)\n",
      "Shape of targets (y): (10992,)\n",
      "NaN counts per column:\n",
      " Attribute1     0\n",
      "Attribute2     0\n",
      "Attribute3     0\n",
      "Attribute4     0\n",
      "Attribute5     0\n",
      "Attribute6     0\n",
      "Attribute7     0\n",
      "Attribute8     0\n",
      "Attribute9     0\n",
      "Attribute10    0\n",
      "Attribute11    0\n",
      "Attribute12    0\n",
      "Attribute13    0\n",
      "Attribute14    0\n",
      "Attribute15    0\n",
      "Attribute16    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to hold processed data\n",
    "processed_dataframes = {}\n",
    "\n",
    "# Process each dataframe in the raw_dataframes dictionary\n",
    "for name, df in raw_dataframes.items():\n",
    "    if name == \"Letters(E, F)\":\n",
    "        y = df.iloc[:, 0]\n",
    "        X = df.iloc[:, 1:]\n",
    "    elif name == \"Mushroom\":\n",
    "        y = df.iloc[:, 0]\n",
    "        X = df.iloc[:, 1:]\n",
    "    elif name == \"DNA\":\n",
    "        y = df.iloc[:, 0].str.strip()\n",
    "        # Remove the second column from the DNA dataframe\n",
    "        X = df.iloc[:, 1:].drop(df.columns[1], axis=1)\n",
    "    else:\n",
    "        X, y = df.iloc[:, :-1], df.iloc[:, -1]\n",
    "\n",
    "    # Limit rows for \"Letters(E, F)\" dataset\n",
    "    if name == \"Letters(E, F)\" and len(X) > 1543:\n",
    "        X = X.iloc[:1543]\n",
    "        y = y.iloc[:1543]\n",
    "\n",
    "\n",
    "    if name == \"Isolet\" and len(X) > 1560:\n",
    "        X = X.iloc[:1560]\n",
    "        y = y.iloc[:1560]\n",
    "        \n",
    "    # Drop columns with only 1 unique value\n",
    "    for col in X.columns:\n",
    "        if len(X[col].unique()) <= 1:\n",
    "            X.drop(columns=[col], inplace=True)\n",
    "\n",
    "    print(f\"Before dropping rows with NaNs in {name}:\")\n",
    "    print(f\"Shape of features (X): {X.shape}\")\n",
    "    print(f\"Shape of targets (y): {y.shape}\")\n",
    "    print(\"NaN counts per column:\\n\", X.isnull().sum())\n",
    "\n",
    "    # Drop rows that contain any NaN values\n",
    "    X.dropna(axis=0, how='any', inplace=True)\n",
    "    # After dropping NaNs, ensure y is aligned with X\n",
    "    y = y[X.index]\n",
    "\n",
    "    print(f\"After dropping rows with NaNs in {name}:\")\n",
    "    print(f\"Shape of features (X): {X.shape}\")\n",
    "    print(f\"Shape of targets (y): {y.shape}\")\n",
    "    print(\"NaN counts per column:\\n\", X.isnull().sum())\n",
    "\n",
    "\n",
    "    # Store processed data in processed_dataframes dictionary\n",
    "    processed_dataframes[name] = {'features': X, 'targets': y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43c3e7b4-c0f0-45aa-ab5b-16e02ed4fde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical(df, categorical_columns):\n",
    "    \"\"\"\n",
    "    Encode non-numeric categorical columns to numeric categories.\n",
    "\n",
    "    Args:\n",
    "    df (pandas.DataFrame): DataFrame containing the data.\n",
    "    categorical_columns (list of str): List of column names to encode.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame with encoded columns.\n",
    "    \"\"\"\n",
    "    label_encoders = {}\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        label_encoders[col] = le  # Store encoder to allow inverse_transform if needed\n",
    "    return df, label_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f46737e-86cf-4f10-993f-5c92aea51d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_datasets(dataframes):\n",
    "    if 'Zoo' in dataframes:\n",
    "        zoo_df = dataframes['Zoo']['features']\n",
    "        if 0 in zoo_df.columns:\n",
    "            zoo_df = zoo_df.drop(columns=[0])\n",
    "        else:\n",
    "            zoo_df = zoo_df.drop(columns=zoo_df.columns[0])\n",
    "        dataframes['Zoo']['features'] = zoo_df\n",
    "\n",
    "    if 'Heart Disease' in dataframes:\n",
    "        hd_df = dataframes['Heart Disease']['features']\n",
    "        columns_to_drop = [hd_df.columns[i] for i in [0, 3, 4, 7, 9] if i < len(hd_df.columns)]\n",
    "        hd_df = hd_df.drop(columns=columns_to_drop)\n",
    "        dataframes['Heart Disease']['features'] = hd_df\n",
    "        y_hd = dataframes['Heart Disease']['targets']\n",
    "        dataframes['Heart Disease']['targets'] = y_hd.apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "    if 'Breast Cancer' in dataframes:\n",
    "        bcw_df = dataframes['Breast Cancer']['features']\n",
    "        bcw_df = bcw_df.drop(columns=bcw_df.columns[0])\n",
    "        dataframes['Breast Cancer']['features'] = bcw_df\n",
    "\n",
    "    if 'Dermatology' in dataframes:\n",
    "        derm_df = dataframes['Dermatology']['features']\n",
    "        derm_df = derm_df.drop(columns=derm_df.columns[-1])\n",
    "        dataframes['Dermatology']['features'] = derm_df\n",
    "\n",
    "    if 'Letters(E, F)' in dataframes:\n",
    "        lr_ef_df = dataframes['Letters(E, F)']['features']\n",
    "        lr_ef_targets = dataframes['Letters(E, F)']['targets']\n",
    "        mask = lr_ef_targets.isin(['E', 'F'])\n",
    "        dataframes['Letters(E, F)']['features'] = lr_ef_df[mask]\n",
    "        dataframes['Letters(E, F)']['targets'] = lr_ef_targets[mask]\n",
    "\n",
    "    if 'DNA' in dataframes:\n",
    "        dna_df = dataframes['DNA']['features']\n",
    "        # Encoding DNA sequences\n",
    "        dna_df, _ = encode_categorical(dna_df, dna_df.columns.tolist())\n",
    "        dataframes['DNA']['features'] = dna_df\n",
    "\n",
    "    if 'Mushroom' in dataframes:\n",
    "        mushroom_df = dataframes['Mushroom']['features']\n",
    "        # Assuming all columns in Mushroom dataset are categorical and need encoding\n",
    "        mushroom_df, _ = encode_categorical(mushroom_df, mushroom_df.columns.tolist())\n",
    "        dataframes['Mushroom']['features'] = mushroom_df\n",
    "\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16a90a8d-cb01-40d6-b0b8-ccb04830abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = preprocess_datasets(processed_dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7513e2a9-293b-486b-97d2-0f290ad504e2",
   "metadata": {},
   "source": [
    "# Clustering Ensemble on Numerical Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb47ce49-900a-4583-b0e3-69e85c3b20a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple_kmeans(features, n_clusters, n_runs):\n",
    "    all_labels = []\n",
    "    for i in range(n_runs):\n",
    "        random_state = random.randint(0, 1000)\n",
    "        kmeans = KMeans(n_clusters=n_clusters, init='k-means++', random_state=random_state, n_init=10)\n",
    "        labels = kmeans.fit_predict(features)\n",
    "        all_labels.append(labels)\n",
    "    return np.array(all_labels).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82fec397-5ff2-48ff-8126-9f43766a02e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in datasets_ensemble:\n",
    "    # Extracting features and targets from the preloaded datasets\n",
    "    features = dataframes[dataset_name][\"features\"]\n",
    "    targets = dataframes[dataset_name][\"targets\"]\n",
    "\n",
    "    # Converting targets to numerical labels if they aren't already\n",
    "    if targets.dtype.kind in 'O':  # Check if targets are object type (e.g., strings)\n",
    "        targets = LabelEncoder().fit_transform(targets)\n",
    "\n",
    "    # Determine the number of clusters from the unique elements in targets\n",
    "    n_clusters = len(np.unique(targets))\n",
    "\n",
    "    # Run multiple k-means and collect results\n",
    "    ensembled_features = run_multiple_kmeans(features, n_clusters, num_runs)\n",
    "    \n",
    "    # Convert numpy array to DataFrame and replace the original data\n",
    "    ensembled_features_df = pd.DataFrame(ensembled_features, index=features.index)\n",
    "    dataframes[dataset_name][\"features\"] = ensembled_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a367cf-a297-42c6-ac78-c6615690841a",
   "metadata": {},
   "source": [
    "# Bernoulli Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d6ede1c-ef58-4510-8743-b4eff77a90ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "\n",
    "class BernoulliMixture:\n",
    "    def __init__(self, n_components, max_iter, tol=1e-3):\n",
    "        self.n_components = n_components\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "\n",
    "    def fit(self,x):\n",
    "        self.x = x\n",
    "        self.init_params()\n",
    "        log_bernoullis = self.get_log_bernoullis(self.x)\n",
    "        self.old_logL = self.get_log_likelihood(log_bernoullis)\n",
    "        for step in range(self.max_iter):\n",
    "            if step > 0:\n",
    "                self.old_logL = self.logL\n",
    "            # E-Step\n",
    "            self.gamma = self.get_responsibilities(log_bernoullis)\n",
    "            self.remember_params()\n",
    "            # M-Step\n",
    "            self.get_Neff()\n",
    "            self.get_mu()\n",
    "            self.get_pi()\n",
    "            # Compute new log_likelihood:\n",
    "            log_bernoullis = self.get_log_bernoullis(self.x)\n",
    "            self.logL = self.get_log_likelihood(log_bernoullis)\n",
    "            if np.isnan(self.logL):\n",
    "                self.reset_params()\n",
    "                break\n",
    "\n",
    "    def reset_params(self):\n",
    "        self.mu = self.old_mu.copy()\n",
    "        self.pi = self.old_pi.copy()\n",
    "        self.gamma = self.old_gamma.copy()\n",
    "        self.get_Neff()\n",
    "        log_bernoullis = self.get_log_bernoullis(self.x)\n",
    "        self.logL = self.get_log_likelihood(log_bernoullis)\n",
    "\n",
    "    def remember_params(self):\n",
    "        self.old_mu = self.mu.copy()\n",
    "        self.old_pi = self.pi.copy()\n",
    "        self.old_gamma = self.gamma.copy()\n",
    "\n",
    "    def init_params(self):\n",
    "        self.n_samples = self.x.shape[0]\n",
    "        self.n_features = self.x.shape[1]\n",
    "        self.pi = 1/self.n_components * np.ones(self.n_components)\n",
    "        self.mu = np.random.RandomState(seed=0).uniform(low=0.25, high=0.75, size=(self.n_components, self.n_features))\n",
    "        self.normalize_mu()\n",
    "\n",
    "    def normalize_mu(self):\n",
    "        sum_over_features = np.sum(self.mu, axis=1)\n",
    "        for k in range(self.n_components):\n",
    "            self.mu[k,:] /= sum_over_features[k]\n",
    "\n",
    "    def get_responsibilities(self, log_bernoullis):\n",
    "        gamma = np.zeros(shape=(log_bernoullis.shape[0], self.n_components))\n",
    "        Z =  logsumexp(np.log(self.pi[None,:]) + log_bernoullis, axis=1)\n",
    "        for k in range(self.n_components):\n",
    "            gamma[:, k] = np.exp(np.log(self.pi[k]) + log_bernoullis[:,k] - Z)\n",
    "        return gamma\n",
    "\n",
    "    def get_log_bernoullis(self, x):\n",
    "        log_bernoullis = self.get_save_single(x, self.mu)\n",
    "        log_bernoullis += self.get_save_single(1-x, 1-self.mu)\n",
    "        return log_bernoullis\n",
    "\n",
    "    # Modified\n",
    "    def get_save_single(self, x, mu):\n",
    "        # Ensure x and mu are numpy arrays with float type\n",
    "        x = np.array(x, dtype=np.float64)\n",
    "        mu = np.array(mu, dtype=np.float64)\n",
    "\n",
    "        # Avoid taking log of zero by setting a minimum value\n",
    "        mu_place = np.where(mu <= 1e-15, 1e-15, mu)\n",
    "        # Perform the tensor dot product safely\n",
    "        try:\n",
    "            result = np.tensordot(x, np.log(mu_place), axes=(1, 1))\n",
    "        except TypeError as e:\n",
    "            print(\"TypeError encountered:\", e)\n",
    "            print(\"x shape:\", x.shape, \"x dtype:\", x.dtype)\n",
    "            print(\"mu_place shape:\", mu_place.shape, \"mu_place dtype:\", mu_place.dtype)\n",
    "            raise\n",
    "\n",
    "        return result\n",
    "\n",
    "    def get_Neff(self):\n",
    "        self.Neff = np.sum(self.gamma, axis=0)\n",
    "\n",
    "    def get_mu(self):\n",
    "        self.mu = np.einsum('ik,id -> kd', self.gamma, self.x) / self.Neff[:,None] \n",
    "\n",
    "    def get_pi(self):\n",
    "        self.pi = self.Neff / self.n_samples\n",
    "\n",
    "    def predict(self, x):\n",
    "        log_bernoullis = self.get_log_bernoullis(x)\n",
    "        gamma = self.get_responsibilities(log_bernoullis)\n",
    "        return np.argmax(gamma, axis=1)\n",
    "\n",
    "    def get_sample_log_likelihood(self, log_bernoullis):\n",
    "        return logsumexp(np.log(self.pi[None,:]) + log_bernoullis, axis=1)\n",
    "\n",
    "    def get_log_likelihood(self, log_bernoullis):\n",
    "        return np.mean(self.get_sample_log_likelihood(log_bernoullis))\n",
    "\n",
    "    def score(self, x):\n",
    "        log_bernoullis = self.get_log_bernoullis(x)\n",
    "        return self.get_log_likelihood(log_bernoullis)\n",
    "\n",
    "    def score_samples(self, x):\n",
    "        log_bernoullis = self.get_log_bernoullis(x)\n",
    "        return self.get_sample_log_likelihood(log_bernoullis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6bc928-010b-4254-aa50-d320fbe89c66",
   "metadata": {},
   "source": [
    "# Schotastic Bernoulli Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "76881bc5-e0b2-40c6-b987-da8b9aaf1580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "\n",
    "class StochasticBernoulliMixture:\n",
    "\n",
    "    def __init__(self, n_components, max_iter, tol=1e-3, batch_size=100):\n",
    "        self.n_components = n_components\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.batch_size = batch_size  # Added line: Initialize batch size\n",
    "\n",
    "    def fit(self, x):\n",
    "        self.x = x\n",
    "        self.init_params()\n",
    "        n_samples = x.shape[0]\n",
    "        batch_size = min(self.batch_size, n_samples)\n",
    "\n",
    "        for step in range(self.max_iter):\n",
    "            indices = np.random.choice(n_samples, batch_size, replace=False)\n",
    "            x_batch = x[indices]\n",
    "\n",
    "            if step > 0:\n",
    "                self.old_logL = self.logL\n",
    "\n",
    "            log_bernoullis = self.get_log_bernoullis(x_batch)\n",
    "            self.gamma = self.get_responsibilities(log_bernoullis)\n",
    "            self.remember_params()\n",
    "\n",
    "            self.get_Neff()\n",
    "            self.get_mu(x_batch)\n",
    "            self.get_pi()\n",
    "\n",
    "            log_bernoullis = self.get_log_bernoullis(x)\n",
    "            self.logL = self.get_log_likelihood(log_bernoullis)\n",
    "\n",
    "            if np.isnan(self.logL):\n",
    "                self.reset_params()\n",
    "                break\n",
    "\n",
    "    def reset_params(self):\n",
    "        self.mu = self.old_mu.copy()\n",
    "        self.pi = self.old_pi.copy()\n",
    "        self.gamma = self.old_gamma.copy()\n",
    "        self.get_Neff()\n",
    "        log_bernoullis = self.get_log_bernoullis(self.x)\n",
    "        self.logL = self.get_log_likelihood(log_bernoullis)\n",
    "\n",
    "    def remember_params(self):\n",
    "        self.old_mu = self.mu.copy()\n",
    "        self.old_pi = self.pi.copy()\n",
    "        self.old_gamma = self.gamma.copy()\n",
    "\n",
    "    def init_params(self):\n",
    "        self.n_samples = self.x.shape[0]\n",
    "        self.n_features = self.x.shape[1]\n",
    "        self.pi = 1/self.n_components * np.ones(self.n_components)\n",
    "        self.mu = np.random.RandomState(seed=0).uniform(low=0.25, high=0.75, size=(self.n_components, self.n_features))\n",
    "        self.normalize_mu()\n",
    "\n",
    "    def normalize_mu(self):\n",
    "        sum_over_features = np.sum(self.mu, axis=1)\n",
    "        for k in range(self.n_components):\n",
    "            self.mu[k,:] /= sum_over_features[k]\n",
    "\n",
    "    def get_responsibilities(self, log_bernoullis):\n",
    "        gamma = np.zeros(shape=(log_bernoullis.shape[0], self.n_components))\n",
    "        Z =  logsumexp(np.log(self.pi[None,:]) + log_bernoullis, axis=1)\n",
    "        for k in range(self.n_components):\n",
    "            gamma[:, k] = np.exp(np.log(self.pi[k]) + log_bernoullis[:,k] - Z)\n",
    "        return gamma\n",
    "\n",
    "    def get_log_bernoullis(self, x):\n",
    "        log_bernoullis = self.get_save_single(x, self.mu)\n",
    "        log_bernoullis += self.get_save_single(1-x, 1-self.mu)\n",
    "        return log_bernoullis\n",
    "\n",
    "    # Modified\n",
    "    def get_save_single(self, x, mu):\n",
    "        # Ensure x and mu are numpy arrays with float type\n",
    "        x = np.array(x, dtype=np.float64)\n",
    "        mu = np.array(mu, dtype=np.float64)\n",
    "\n",
    "        # Avoid taking log of zero by setting a minimum value\n",
    "        mu_place = np.where(mu <= 1e-15, 1e-15, mu)\n",
    "        # Perform the tensor dot product safely\n",
    "        try:\n",
    "            result = np.tensordot(x, np.log(mu_place), axes=(1, 1))\n",
    "        except TypeError as e:\n",
    "            print(\"TypeError encountered:\", e)\n",
    "            print(\"x shape:\", x.shape, \"x dtype:\", x.dtype)\n",
    "            print(\"mu_place shape:\", mu_place.shape, \"mu_place dtype:\", mu_place.dtype)\n",
    "            raise\n",
    "\n",
    "        return result\n",
    "\n",
    "    def get_Neff(self):\n",
    "        self.Neff = np.sum(self.gamma, axis=0)\n",
    "\n",
    "    def get_mu(self, x):\n",
    "        self.mu = np.einsum('ik,id -> kd', self.gamma, x) / self.Neff[:, None]\n",
    "\n",
    "    def get_pi(self):\n",
    "        self.pi = self.Neff / self.n_samples\n",
    "\n",
    "    def predict(self, x):\n",
    "        log_bernoullis = self.get_log_bernoullis(x)\n",
    "        gamma = self.get_responsibilities(log_bernoullis)\n",
    "        return np.argmax(gamma, axis=1)\n",
    "\n",
    "    def get_sample_log_likelihood(self, log_bernoullis):\n",
    "        return logsumexp(np.log(self.pi[None,:]) + log_bernoullis, axis=1)\n",
    "\n",
    "    def get_log_likelihood(self, log_bernoullis):\n",
    "        return np.mean(self.get_sample_log_likelihood(log_bernoullis))\n",
    "\n",
    "    def score(self, x):\n",
    "        log_bernoullis = self.get_log_bernoullis(x)\n",
    "        return self.get_log_likelihood(log_bernoullis)\n",
    "\n",
    "    def score_samples(self, x):\n",
    "        log_bernoullis = self.get_log_bernoullis(x)\n",
    "        return self.get_sample_log_likelihood(log_bernoullis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cda681d-b891-4dfa-b0d9-5adf23d006de",
   "metadata": {},
   "source": [
    "# Kmodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "092ff75a-0736-4e41-940b-2a50beca0390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_kmodes(features, n_clusters):\n",
    "    \"\"\"Perform clustering using KModes algorithm.\"\"\"\n",
    "    km = KModes(n_clusters=n_clusters, init='random', n_init=5)\n",
    "    clusters = km.fit_predict(features)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ba7dce-7c00-4f40-ab2e-aeee8f9749ae",
   "metadata": {},
   "source": [
    "# Running the Schotastic Bernoulli Mixture Model, Bernoulli Mixture Model, Kmodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d7a3ff2f-662f-46fc-bb92-8975dfe3662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(features):\n",
    "    if 'sequence' in features.columns:\n",
    "        # Assuming DNA sequences are stored in 'sequence' column\n",
    "        features['encoded_sequence'] = encode_dna_sequences(features['sequence'])\n",
    "        features.drop('sequence', axis=1, inplace=True)  # Remove the original sequence column\n",
    "        return features['encoded_sequence']\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "45c9f2ab-c3c2-4971-86de-ee77f20f86a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(true_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    Calculate clustering metrics: Adjusted Rand Index, Normalized Mutual Information, and Fowlkes-Mallows Index.\n",
    "    \n",
    "    Args:\n",
    "    true_labels (array-like): True cluster labels.\n",
    "    predicted_labels (array-like): Cluster labels predicted by a clustering algorithm.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing the ARI, NMI, and FMI scores.\n",
    "    \"\"\"\n",
    "    ari_score = ARI(true_labels, predicted_labels)\n",
    "    nmi_score = NMI(true_labels, predicted_labels)\n",
    "    fmi_score = FMI(true_labels, predicted_labels)\n",
    "    return ari_score, nmi_score, fmi_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d6edc8dc-de9a-4a78-879f-4ed2442c0e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def run_clustering_algorithms(dataframes, n_clusters_dict, num_runs=10):\n",
    "    results_list = []\n",
    "    for name, data in dataframes.items():\n",
    "        print(\"Processing:\", name)\n",
    "        features = data['features']\n",
    "        true_labels = data['targets'].squeeze()\n",
    "        n_clusters = n_clusters_dict.get(name, 2)\n",
    "\n",
    "        metrics = {'KModes': [], 'BernoulliMixture': [], 'StochasticBernoulliMixture': []}\n",
    "\n",
    "        features_encoded = OneHotEncoder(sparse_output=False).fit_transform(features)\n",
    "\n",
    "        for _ in range(num_runs):\n",
    "            # K-Modes\n",
    "            km_clusters = perform_kmodes(features, n_clusters)\n",
    "            ari, nmi, fmi = calculate_metrics(true_labels, km_clusters)\n",
    "            metrics['KModes'].append((ari, nmi, fmi))\n",
    "\n",
    "            # Original Bernoulli Mixture\n",
    "            bm = BernoulliMixture(n_components=n_clusters, max_iter=1000)\n",
    "            bm.fit(features_encoded)\n",
    "            bm_clusters = bm.predict(features_encoded)\n",
    "            ari, nmi, fmi = calculate_metrics(true_labels, bm_clusters)\n",
    "            metrics['BernoulliMixture'].append((ari, nmi, fmi))\n",
    "\n",
    "            # Stochastic Bernoulli Mixture\n",
    "            sbm = StochasticBernoulliMixture(n_components=n_clusters, max_iter=1000, batch_size=100)\n",
    "            sbm.fit(features_encoded)\n",
    "            sbm_clusters = sbm.predict(features_encoded)\n",
    "            ari, nmi, fmi = calculate_metrics(true_labels, sbm_clusters)\n",
    "            metrics['StochasticBernoulliMixture'].append((ari, nmi, fmi))\n",
    "\n",
    "        # Calculate mean and standard deviation for each method and append to results list\n",
    "        for method, values in metrics.items():\n",
    "            ari_vals, nmi_vals, fmi_vals = zip(*values)  # Unpack the metrics values\n",
    "            ari_mean, ari_std = np.mean(ari_vals), np.std(ari_vals)\n",
    "            nmi_mean, nmi_std = np.mean(nmi_vals), np.std(nmi_vals)\n",
    "            fmi_mean, fmi_std = np.mean(fmi_vals), np.std(fmi_vals)  # Calculate mean and std for FMI\n",
    "            results_list.append({\n",
    "                \"Dataset\": name,\n",
    "                \"Method\": method,\n",
    "                \"ARI\": f\"{ari_mean:.4f}{ari_std:.2f}\",\n",
    "                \"NMI\": f\"{nmi_mean:.4f}{nmi_std:.2f}\",\n",
    "                \"FMI\": f\"{fmi_mean:.4f}{fmi_std:.2f}\"  # Include FMI in results\n",
    "            })\n",
    "\n",
    "    # Convert list of dictionaries to DataFrame for results\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b5a059f9-d5d5-4ebd-a490-676da8067818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_results(results_df):\n",
    "    # Include 'FMI' in the list of columns to be melted along with 'ARI' and 'NMI'\n",
    "    expanded_df = pd.melt(results_df, id_vars=[\"Dataset\", \"Method\"], value_vars=[\"ARI\", \"NMI\", \"FMI\"], var_name=\"Metric\", value_name=\"Value\")\n",
    "    \n",
    "    # Split the 'Value' column into 'Metric_Value' and 'Std', assuming the format \"valuestd\"\n",
    "    expanded_df[['Metric_Value', 'Std']] = expanded_df['Value'].str.split('', expand=True)\n",
    "    expanded_df.drop(columns=['Value'], inplace=True)  # Removing the original combined column\n",
    "    \n",
    "    # Convert the 'Metric_Value' and 'Std' columns to numeric types for further operations\n",
    "    expanded_df['Metric_Value'] = expanded_df['Metric_Value'].astype(float)\n",
    "    expanded_df['Std'] = expanded_df['Std'].astype(float)\n",
    "\n",
    "    # Reformat 'Metric_Value' to combine mean and standard deviation into a single string formatted as needed\n",
    "    expanded_df['Metric_Value'] = expanded_df['Metric_Value'].map('{:.4f}'.format) + \"\" + expanded_df['Std'].map('{:.2f}'.format)\n",
    "    \n",
    "    # Ensuring the order of datasets and methods remains consistent with the original DataFrame\n",
    "    dataset_order = results_df['Dataset'].unique()\n",
    "    method_order = results_df['Method'].unique()\n",
    "\n",
    "    # Creating a pivot table to restructure the DataFrame\n",
    "    # This pivot table organizes the data by 'Dataset' and 'Metric', with methods as columns and metric values as cell data\n",
    "    pivot_df = expanded_df.pivot_table(index=[\"Dataset\", \"Metric\"], columns=\"Method\", values=\"Metric_Value\", aggfunc='first')\n",
    "    \n",
    "    # Reindexing the pivot table to maintain the original order\n",
    "    pivot_df = pivot_df.reindex(dataset_order, level='Dataset')\n",
    "    pivot_df = pivot_df.reindex(method_order, axis='columns')\n",
    "\n",
    "    return pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "62b68fd2-7397-416c-be50-0851f901453d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Soybean\n",
      "Processing: Zoo\n",
      "Processing: Heart Disease\n",
      "Processing: Breast Cancer\n",
      "Processing: Dermatology\n",
      "Processing: Letters(E, F)\n",
      "Processing: DNA\n",
      "Processing: Mushroom\n",
      "Processing: Iris\n",
      "Processing: Isolet\n",
      "Processing: Optical\n",
      "Processing: PenDigits\n"
     ]
    }
   ],
   "source": [
    "# Running all algorithms and storing the results\n",
    "results = run_clustering_algorithms(dataframes, num_clusters_dict, num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2564d50c-43bd-4516-ab9d-d7ccb3628920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function to reformat the results\n",
    "formatted_results = reformat_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc165ce7-5459-46a2-8ae2-e0507f12b20d",
   "metadata": {},
   "source": [
    "# Presentation of Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f1888d65-f694-42e1-92d5-31c7795ce69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Number of Samples</th>\n",
       "      <th>Number of Features</th>\n",
       "      <th>Number of Unique Values in Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Soybean</td>\n",
       "      <td>47</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zoo</td>\n",
       "      <td>101</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>297</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>683</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dermatology</td>\n",
       "      <td>358</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Letters(E, F)</td>\n",
       "      <td>103</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DNA</td>\n",
       "      <td>3190</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mushroom</td>\n",
       "      <td>5644</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Iris</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Isolet</td>\n",
       "      <td>1558</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Optical</td>\n",
       "      <td>5620</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PenDigits</td>\n",
       "      <td>10992</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name  Number of Samples  Number of Features  \\\n",
       "0         Soybean                 47                  21   \n",
       "1             Zoo                101                  16   \n",
       "2   Heart Disease                297                   8   \n",
       "3   Breast Cancer                683                   9   \n",
       "4     Dermatology                358                  33   \n",
       "5   Letters(E, F)                103                  16   \n",
       "6             DNA               3190                  60   \n",
       "7        Mushroom               5644                  21   \n",
       "8            Iris                150                  10   \n",
       "9          Isolet               1558                  10   \n",
       "10        Optical               5620                  10   \n",
       "11      PenDigits              10992                  10   \n",
       "\n",
       "    Number of Unique Values in Target  \n",
       "0                                   4  \n",
       "1                                   7  \n",
       "2                                   2  \n",
       "3                                   2  \n",
       "4                                   6  \n",
       "5                                   2  \n",
       "6                                   3  \n",
       "7                                   6  \n",
       "8                                   3  \n",
       "9                                  26  \n",
       "10                                 10  \n",
       "11                                 10  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data for the table\n",
    "table_data = []\n",
    "\n",
    "for name, content in dataframes.items():\n",
    "    X, y = content['features'], content['targets']\n",
    "    table_data.append({\n",
    "        \"Name\": name,\n",
    "        \"Number of Samples\": X.shape[0],\n",
    "        \"Number of Features\": X.shape[1],\n",
    "        \"Number of Unique Values in Target\": len(pd.unique(y))\n",
    "    })\n",
    "\n",
    "# Convert table data into a DataFrame for pretty printing\n",
    "table_df = pd.DataFrame(table_data)\n",
    "table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0790c488-c246-4541-9b32-36bf1a76e808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>KModes</th>\n",
       "      <th>BernoulliMixture</th>\n",
       "      <th>StochasticBernoulliMixture</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Soybean</th>\n",
       "      <th>ARI</th>\n",
       "      <td>0.87990.15</td>\n",
       "      <td>1.00000.00</td>\n",
       "      <td>1.00000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FMI</th>\n",
       "      <td>0.91370.11</td>\n",
       "      <td>1.00000.00</td>\n",
       "      <td>1.00000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMI</th>\n",
       "      <td>0.92530.09</td>\n",
       "      <td>1.00000.00</td>\n",
       "      <td>1.00000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Zoo</th>\n",
       "      <th>ARI</th>\n",
       "      <td>0.70000.14</td>\n",
       "      <td>0.69720.00</td>\n",
       "      <td>0.72670.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FMI</th>\n",
       "      <td>0.76580.11</td>\n",
       "      <td>0.76450.00</td>\n",
       "      <td>0.78820.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMI</th>\n",
       "      <td>0.78930.05</td>\n",
       "      <td>0.80280.00</td>\n",
       "      <td>0.82020.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Heart Disease</th>\n",
       "      <th>ARI</th>\n",
       "      <td>0.34060.04</td>\n",
       "      <td>0.32920.00</td>\n",
       "      <td>0.16280.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FMI</th>\n",
       "      <td>0.67390.02</td>\n",
       "      <td>0.66460.00</td>\n",
       "      <td>0.61510.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMI</th>\n",
       "      <td>0.26840.02</td>\n",
       "      <td>0.25980.00</td>\n",
       "      <td>0.19000.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Breast Cancer</th>\n",
       "      <th>ARI</th>\n",
       "      <td>0.74380.05</td>\n",
       "      <td>0.88000.00</td>\n",
       "      <td>0.04970.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FMI</th>\n",
       "      <td>0.88760.02</td>\n",
       "      <td>0.94450.00</td>\n",
       "      <td>0.59180.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMI</th>\n",
       "      <td>0.63970.04</td>\n",
       "      <td>0.81520.00</td>\n",
       "      <td>0.23900.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Dermatology</th>\n",
       "      <th>ARI</th>\n",
       "      <td>0.52350.12</td>\n",
       "      <td>0.77180.00</td>\n",
       "      <td>0.73240.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FMI</th>\n",
       "      <td>0.62280.10</td>\n",
       "      <td>0.81880.00</td>\n",
       "      <td>0.80310.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMI</th>\n",
       "      <td>0.63040.07</td>\n",
       "      <td>0.82910.00</td>\n",
       "      <td>0.78250.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Letters(E, F)</th>\n",
       "      <th>ARI</th>\n",
       "      <td>0.38990.08</td>\n",
       "      <td>0.01170.00</td>\n",
       "      <td>0.00310.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FMI</th>\n",
       "      <td>0.70290.03</td>\n",
       "      <td>0.51060.00</td>\n",
       "      <td>0.57390.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMI</th>\n",
       "      <td>0.33030.06</td>\n",
       "      <td>0.01350.00</td>\n",
       "      <td>0.01320.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DNA</th>\n",
       "      <th>ARI</th>\n",
       "      <td>0.02790.01</td>\n",
       "      <td>0.85890.00</td>\n",
       "      <td>0.04920.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FMI</th>\n",
       "      <td>0.37720.00</td>\n",
       "      <td>0.91320.00</td>\n",
       "      <td>0.61150.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMI</th>\n",
       "      <td>0.04300.01</td>\n",
       "      <td>0.77790.00</td>\n",
       "      <td>0.07830.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Mushroom</th>\n",
       "      <th>ARI</th>\n",
       "      <td>-0.01390.00</td>\n",
       "      <td>-0.00050.00</td>\n",
       "      <td>-0.01810.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FMI</th>\n",
       "      <td>0.52300.00</td>\n",
       "      <td>0.47470.00</td>\n",
       "      <td>0.49480.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMI</th>\n",
       "      <td>0.02020.00</td>\n",
       "      <td>0.04270.00</td>\n",
       "      <td>0.03420.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Iris</th>\n",
       "      <th>ARI</th>\n",
       "      <td>0.73020.00</td>\n",
       "      <td>0.73020.00</td>\n",
       "      <td>0.73020.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FMI</th>\n",
       "      <td>0.82080.00</td>\n",
       "      <td>0.82080.00</td>\n",
       "      <td>0.82080.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMI</th>\n",
       "      <td>0.75820.00</td>\n",
       "      <td>0.75820.00</td>\n",
       "      <td>0.75820.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Isolet</th>\n",
       "      <th>ARI</th>\n",
       "      <td>0.43810.02</td>\n",
       "      <td>0.41220.00</td>\n",
       "      <td>0.28840.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FMI</th>\n",
       "      <td>0.46400.02</td>\n",
       "      <td>0.44040.00</td>\n",
       "      <td>0.36120.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMI</th>\n",
       "      <td>0.71050.01</td>\n",
       "      <td>0.70030.00</td>\n",
       "      <td>0.63760.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Optical</th>\n",
       "      <th>ARI</th>\n",
       "      <td>0.67110.00</td>\n",
       "      <td>0.67600.00</td>\n",
       "      <td>0.58940.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FMI</th>\n",
       "      <td>0.70700.00</td>\n",
       "      <td>0.71450.00</td>\n",
       "      <td>0.65040.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMI</th>\n",
       "      <td>0.75690.00</td>\n",
       "      <td>0.76280.00</td>\n",
       "      <td>0.72900.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">PenDigits</th>\n",
       "      <th>ARI</th>\n",
       "      <td>0.53670.02</td>\n",
       "      <td>0.53200.00</td>\n",
       "      <td>0.48950.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FMI</th>\n",
       "      <td>0.59160.02</td>\n",
       "      <td>0.58750.00</td>\n",
       "      <td>0.56090.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMI</th>\n",
       "      <td>0.68200.01</td>\n",
       "      <td>0.68170.00</td>\n",
       "      <td>0.65060.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                      KModes BernoulliMixture StochasticBernoulliMixture\n",
       "Dataset       Metric                                                          \n",
       "Soybean       ARI      0.87990.15      1.00000.00                1.00000.00\n",
       "              FMI      0.91370.11      1.00000.00                1.00000.00\n",
       "              NMI      0.92530.09      1.00000.00                1.00000.00\n",
       "Zoo           ARI      0.70000.14      0.69720.00                0.72670.00\n",
       "              FMI      0.76580.11      0.76450.00                0.78820.00\n",
       "              NMI      0.78930.05      0.80280.00                0.82020.00\n",
       "Heart Disease ARI      0.34060.04      0.32920.00                0.16280.06\n",
       "              FMI      0.67390.02      0.66460.00                0.61510.01\n",
       "              NMI      0.26840.02      0.25980.00                0.19000.03\n",
       "Breast Cancer ARI      0.74380.05      0.88000.00                0.04970.02\n",
       "              FMI      0.88760.02      0.94450.00                0.59180.00\n",
       "              NMI      0.63970.04      0.81520.00                0.23900.01\n",
       "Dermatology   ARI      0.52350.12      0.77180.00                0.73240.11\n",
       "              FMI      0.62280.10      0.81880.00                0.80310.07\n",
       "              NMI      0.63040.07      0.82910.00                0.78250.07\n",
       "Letters(E, F) ARI      0.38990.08      0.01170.00                0.00310.01\n",
       "              FMI      0.70290.03      0.51060.00                0.57390.04\n",
       "              NMI      0.33030.06      0.01350.00                0.01320.02\n",
       "DNA           ARI      0.02790.01      0.85890.00                0.04920.07\n",
       "              FMI      0.37720.00      0.91320.00                0.61150.02\n",
       "              NMI      0.04300.01      0.77790.00                0.07830.08\n",
       "Mushroom      ARI     -0.01390.00     -0.00050.00               -0.01810.00\n",
       "              FMI      0.52300.00      0.47470.00                0.49480.00\n",
       "              NMI      0.02020.00      0.04270.00                0.03420.00\n",
       "Iris          ARI      0.73020.00      0.73020.00                0.73020.00\n",
       "              FMI      0.82080.00      0.82080.00                0.82080.00\n",
       "              NMI      0.75820.00      0.75820.00                0.75820.00\n",
       "Isolet        ARI      0.43810.02      0.41220.00                0.28840.07\n",
       "              FMI      0.46400.02      0.44040.00                0.36120.05\n",
       "              NMI      0.71050.01      0.70030.00                0.63760.03\n",
       "Optical       ARI      0.67110.00      0.67600.00                0.58940.07\n",
       "              FMI      0.70700.00      0.71450.00                0.65040.05\n",
       "              NMI      0.75690.00      0.76280.00                0.72900.02\n",
       "PenDigits     ARI      0.53670.02      0.53200.00                0.48950.05\n",
       "              FMI      0.59160.02      0.58750.00                0.56090.04\n",
       "              NMI      0.68200.01      0.68170.00                0.65060.04"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0077ebe5-43e9-4b13-b36c-b0aa720d6d33",
   "metadata": {},
   "source": [
    "# Analysis Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd2f499-df1e-432a-a35b-184bef56c72e",
   "metadata": {},
   "source": [
    "### Why FMI performs better than NMI and ARI\n",
    "\n",
    "The Fowlkes-Mallows Index (FMI) generally tends to be higher because it is less stringent regarding error typesit emphasizes correctly identified pairs rather than penalizing incorrectly separated or grouped pairs. In contrast, the Adjusted Rand Index (ARI) and Normalized Mutual Information (NMI) more rigorously account for both false positives and false negatives, leading to typically lower scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf7215f-5ec2-4c77-ba25-a2ba16954052",
   "metadata": {},
   "source": [
    "### Why FMI is consistently higher than ARI and NMI:\n",
    "\n",
    "FMI measures the geometric mean of the proportion of pairs correctly identified together (same cluster in both predicted and true labels) and the proportion of pairs in the same cluster in at least one of the predicted or true labels. It tends to emphasize true positives more heavily, resulting in consistently higher scores across all datasets.\n",
    "\n",
    "ARI, however, measures the similarity between two assignments while discounting pairs that are randomly assigned to the same or different clusters. This index accounts for chance pairings, making its scores generally lower than FMI, especially if many pairs are randomly classified.\n",
    "\n",
    "NMI is a normalized version of the Mutual Information (MI) score that evaluates the agreement between true and predicted labels while considering cluster randomness. Its scores typically fall between those of ARI and FMI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285906b5-2691-47d1-9320-6514b0d2b7af",
   "metadata": {},
   "source": [
    "## Conclusion on the different Models: Kmodes, Bernoulli Mixter, Stochastic Bernoulli Mixture\n",
    "The superior performance of Bernoulli-based methods on the Soybean dataset indicates a good fit for datasets with binary or nearly binary data representations.\n",
    "\n",
    "KModes generally performs consistently across various data types but does not excel when data aligns better with binary assumptions.\n",
    "\n",
    "The performance variation across different datasets and metrics for the Stochastic Bernoulli Mixture model suggests that while randomness can sometimes better capture data variability, it can also destabilize the clustering process, particularly when the underlying data structure is complex or not well-understood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda3af31-32bd-4e0b-ae16-d7b9d95aff22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
